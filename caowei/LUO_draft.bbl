% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{maas2011learning}
A.~L. Maas, R.~E. Daly, P.~T. Pham, D.~Huang, A.~Y. Ng, and C.~Potts,
  ``Learning word vectors for sentiment analysis,'' in \emph{Proceedings of the
  49th Annual Meeting of the Association for Computational Linguistics: Human
  Language Technologies-Volume 1}.\hskip 1em plus 0.5em minus 0.4em\relax
  Association for Computational Linguistics, 2011, pp. 142--150.

\bibitem{ghiassi2013twitter}
M.~Ghiassi, J.~Skinner, and D.~Zimbra, ``Twitter brand sentiment analysis: A
  hybrid system using n-gram analysis and dynamic artificial neural network,''
  \emph{Expert Systems with applications}, vol.~40, no.~16, pp. 6266--6282,
  2013.

\bibitem{zhang2003question}
D.~Zhang and W.~S. Lee, ``Question classification using support vector
  machines,'' in \emph{Proceedings of the 26th annual international ACM SIGIR
  conference on Research and development in informaion retrieval}.\hskip 1em
  plus 0.5em minus 0.4em\relax ACM, 2003, pp. 26--32.

\bibitem{li2002learning}
X.~Li and D.~Roth, ``Learning question classifiers,'' in \emph{Proceedings of
  the 19th international conference on Computational linguistics-Volume
  1}.\hskip 1em plus 0.5em minus 0.4em\relax Association for Computational
  Linguistics, 2002, pp. 1--7.

\bibitem{wang2012baselines}
S.~Wang and C.~D. Manning, ``Baselines and bigrams: Simple, good sentiment and
  topic classification,'' in \emph{Proceedings of the 50th Annual Meeting of
  the Association for Computational Linguistics: Short Papers-Volume 2}.\hskip
  1em plus 0.5em minus 0.4em\relax Association for Computational Linguistics,
  2012, pp. 90--94.

\bibitem{quercia2012tweetlda}
D.~Quercia, H.~Askham, and J.~Crowcroft, ``Tweetlda: supervised topic
  classification and link prediction in twitter,'' in \emph{Proceedings of the
  4th Annual ACM Web Science Conference}.\hskip 1em plus 0.5em minus
  0.4em\relax ACM, 2012, pp. 247--250.

\bibitem{joachims2002statistical}
T.~Joachims, ``A statistical learning model of text classification for svms,''
  in \emph{Learning to Classify Text Using Support Vector Machines}.\hskip 1em
  plus 0.5em minus 0.4em\relax Springer, 2002, pp. 45--74.

\bibitem{joachims1998text}
------, ``Text categorization with support vector machines: Learning with many
  relevant features,'' in \emph{European conference on machine learning}.\hskip
  1em plus 0.5em minus 0.4em\relax Springer, 1998, pp. 137--142.

\bibitem{mikolov2010recurrent}
T.~Mikolov, M.~Karafi{\'a}t, L.~Burget, J.~Cernock{\`y}, and S.~Khudanpur,
  ``Recurrent neural network based language model.'' in \emph{Interspeech},
  vol.~2, 2010, p.~3.

\bibitem{johnson2014effective}
R.~Johnson and T.~Zhang, ``Effective use of word order for text categorization
  with convolutional neural networks,'' \emph{arXiv preprint arXiv:1412.1058},
  2014.

\bibitem{socher2013recursive}
R.~Socher, A.~Perelygin, J.~Y. Wu, J.~Chuang, C.~D. Manning, A.~Y. Ng, and
  C.~Potts, ``Recursive deep models for semantic compositionality over a
  sentiment treebank,'' in \emph{Proceedings of the conference on empirical
  methods in natural language processing (EMNLP)}, vol. 1631.\hskip 1em plus
  0.5em minus 0.4em\relax Citeseer, 2013, p. 1642.

\bibitem{elman1990finding}
J.~L. Elman, ``Finding structure in time,'' \emph{Cognitive science}, vol.~14,
  no.~2, pp. 179--211, 1990.

\bibitem{hochreiter1997long}
S.~Hochreiter and J.~Schmidhuber, ``Long short-term memory,'' \emph{Neural
  computation}, vol.~9, no.~8, pp. 1735--1780, 1997.

\bibitem{li2015constructing}
X.~Li and X.~Wu, ``Constructing long short-term memory based deep recurrent
  neural networks for large vocabulary speech recognition,'' in \emph{2015 IEEE
  International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2015, pp. 4520--4524.

\bibitem{breuel2013high}
T.~M. Breuel, A.~Ul-Hasan, M.~A. Al-Azawi, and F.~Shafait, ``High-performance
  ocr for printed english and fraktur using lstm networks,'' in \emph{2013 12th
  International Conference on Document Analysis and Recognition}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2013, pp. 683--687.

\bibitem{sutskever2014sequence}
I.~Sutskever, O.~Vinyals, and Q.~V. Le, ``Sequence to sequence learning with
  neural networks,'' in \emph{Advances in neural information processing
  systems}, 2014, pp. 3104--3112.

\bibitem{lee2016sequential}
J.~Y. Lee and F.~Dernoncourt, ``Sequential short-text classification with
  recurrent and convolutional neural networks,'' \emph{arXiv preprint
  arXiv:1603.03827}, 2016.

\bibitem{zhou2015end}
J.~Zhou and W.~Xu, ``End-to-end learning of semantic role labeling using
  recurrent neural networks,'' in \emph{Proceedings of the Annual Meeting of
  the Association for Computational Linguistics}, 2015.

\bibitem{he2015deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' \emph{arXiv preprint arXiv:1512.03385}, 2015.

\bibitem{vapnik2013nature}
V.~Vapnik, \emph{The nature of statistical learning theory}.\hskip 1em plus
  0.5em minus 0.4em\relax Springer Science \& Business Media, 2013.

\bibitem{le2014distributed}
Q.~V. Le and T.~Mikolov, ``Distributed representations of sentences and
  documents.'' in \emph{ICML}, vol.~14, 2014, pp. 1188--1196.

\bibitem{zhang2015character}
X.~Zhang, J.~Zhao, and Y.~LeCun, ``Character-level convolutional networks for
  text classification,'' in \emph{Advances in Neural Information Processing
  Systems}, 2015, pp. 649--657.

\bibitem{kim2014convolutional}
Y.~Kim, ``Convolutional neural networks for sentence classification,''
  \emph{arXiv preprint arXiv:1408.5882}, 2014.

\bibitem{johnson2015semi}
R.~Johnson and T.~Zhang, ``Semi-supervised convolutional neural networks for
  text categorization via region embedding,'' in \emph{Advances in neural
  information processing systems}, 2015, pp. 919--927.

\bibitem{xiao2016chinese}
Z.~Xiao and P.~Liang, ``Chinese sentiment analysis using bidirectional lstm
  with word embedding,'' in \emph{International Conference on Cloud Computing
  and Security}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2016, pp.
  601--610.

\bibitem{tang2015document}
D.~Tang, B.~Qin, and T.~Liu, ``Document modeling with gated recurrent neural
  network for sentiment classification,'' in \emph{Proceedings of the 2015
  Conference on Empirical Methods in Natural Language Processing}, 2015, pp.
  1422--1432.

\bibitem{lai2015recurrent}
S.~Lai, L.~Xu, K.~Liu, and J.~Zhao, ``Recurrent convolutional neural networks
  for text classification.'' in \emph{AAAI}, 2015, pp. 2267--2273.

\bibitem{wang2016learning}
P.~Wang, Y.~Qian, F.~K. Soong, L.~He, and H.~Zhao, ``Learning distributed word
  representations for bidirectional lstm recurrent neural network,'' in
  \emph{Proc. of ICASSP}, 2016.

\bibitem{wang2016semantic}
P.~Wang, B.~Xu, J.~Xu, G.~Tian, C.-L. Liu, and H.~Hao, ``Semantic expansion
  using word embedding clustering and convolutional neural network for
  improving short text classification,'' \emph{Neurocomputing}, vol. 174, pp.
  806--814, 2016.

\bibitem{liu2016recurrent}
P.~Liu, X.~Qiu, and X.~Huang, ``Recurrent neural network for text
  classification with multi-task learning,'' \emph{arXiv preprint
  arXiv:1605.05101}, 2016.

\bibitem{graves2005framewise}
A.~Graves and J.~Schmidhuber, ``Framewise phoneme classification with
  bidirectional lstm and other neural network architectures,'' \emph{Neural
  Networks}, vol.~18, no.~5, pp. 602--610, 2005.

\bibitem{nair2010rectified}
V.~Nair and G.~E. Hinton, ``Rectified linear units improve restricted boltzmann
  machines,'' in \emph{Proceedings of the 27th International Conference on
  Machine Learning (ICML-10)}, 2010, pp. 807--814.

\bibitem{graves2013speech}
A.~Graves, A.-r. Mohamed, and G.~Hinton, ``Speech recognition with deep
  recurrent neural networks,'' in \emph{2013 IEEE international conference on
  acoustics, speech and signal processing}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2013, pp. 6645--6649.

\bibitem{chung2015gated}
J.~Chung, C.~G{\"u}l{\c{c}}ehre, K.~Cho, and Y.~Bengio, ``Gated feedback
  recurrent neural networks,'' \emph{CoRR, abs/1502.02367}, 2015.

\bibitem{kingma2014adam}
D.~Kingma and J.~Ba, ``Adam: A method for stochastic optimization,''
  \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{kalchbrenner2014convolutional}
N.~Kalchbrenner, E.~Grefenstette, and P.~Blunsom, ``A convolutional neural
  network for modelling sentences,'' \emph{arXiv preprint arXiv:1404.2188},
  2014.

\bibitem{irsoy2014deep}
O.~Irsoy and C.~Cardie, ``Deep recursive neural networks for compositionality
  in language,'' in \emph{Advances in Neural Information Processing Systems},
  2014, pp. 2096--2104.

\bibitem{tai2015improved}
K.~S. Tai, R.~Socher, and C.~D. Manning, ``Improved semantic representations
  from tree-structured long short-term memory networks,'' \emph{arXiv preprint
  arXiv:1503.00075}, 2015.

\bibitem{zhou2015c}
C.~Zhou, C.~Sun, Z.~Liu, and F.~Lau, ``A c-lstm neural network for text
  classification,'' \emph{arXiv preprint arXiv:1511.08630}, 2015.

\bibitem{hinton2012improving}
G.~E. Hinton, N.~Srivastava, A.~Krizhevsky, I.~Sutskever, and R.~R.
  Salakhutdinov, ``Improving neural networks by preventing co-adaptation of
  feature detectors,'' \emph{arXiv preprint arXiv:1207.0580}, 2012.

\end{thebibliography}
