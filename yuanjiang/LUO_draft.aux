\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Table of contents}{i}{section*.1}}
\citation{vd2d3d}
\citation{isbi12}
\citation{watershed}
\citation{vd2d3d}
\citation{cedn}
\@writefile{toc}{\contentsline {chapter}{List of figures}{iii}{section*.3}}
\citation{cedn}
\citation{vd2d3d}
\citation{cedn}
\@writefile{toc}{\contentsline {chapter}{List of tables}{v}{section*.5}}
\citation{???}
\citation{encoder-decoder}
\citation{edgebox}
\citation{vd2d3d}
\citation{fusionnet}
\citation{unet}
\citation{canny}
\citation{sobel}
\citation{se}
\citation{deep contour}
\citation{etc}
\citation{hed}
\citation{hed}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{introduction}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background and Motivation}{1}{section.1.1}}
\citation{wikipedia}
\citation{fcn}
\citation{encoder-decoder}
\citation{hed}
\citation{m2fcn23}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Application Scenes}{2}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}EM Images}{2}{subsection.1.2.1}}
\citation{N4}
\citation{Vd2d3d}
\citation{fusionnet}
\citation{etc}
\citation{m2fcn43}
\citation{hed}
\citation{canny}
\citation{sobel}
\citation{ets}
\citation{N4}
\citation{vd2d3d}
\citation{etc}
\citation{piriform}
\citation{isbi2012}
\citation{cedn3}
\citation{cedn41}
\citation{cedn15}
\citation{cedn18}
\citation{bcf}
\citation{bsp}
\citation{bcsp}
\citation{canny}
\citation{sobel}
\citation{etc}
\citation{voc}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Natural Images}{4}{subsection.1.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Organization of the thesis}{4}{section.1.3}}
\citation{canny}
\citation{sobel}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related Work}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{related work}{{2}{7}{Related Work}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Traditional edge detection}{7}{section.2.1}}
\citation{cedn37}
\citation{3}
\citation{30}
\citation{12}
\citation{sliding window}
\citation{cedn3}
\citation{se}
\citation{alexnet}
\citation{vgg}
\citation{googlenet}
\citation{resnet}
\citation{alexnet}
\citation{rcnn series}
\citation{deep mask}
\citation{deep contour}
\citation{deep contour23}
\citation{19}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Hand-crafted feature based methods}{8}{subsection.2.1.1}}
\citation{sketch token}
\citation{deep contour}
\citation{deep contour}
\citation{se}
\citation{deep contour}
\citation{fcn}
\citation{voc2007}
\citation{2012}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Deep learning based methods}{9}{subsection.2.1.2}}
\citation{hed}
\citation{hed}
\citation{hed}
\citation{bsds500}
\citation{bsds500}
\citation{deep contour}
\citation{hed}
\citation{deep contour}
\citation{se}
\citation{gpb}
\citation{cedn}
\citation{cedn}
\citation{vgg}
\citation{cedn}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Object Boundary Detection in Natural Images}{10}{section.2.2}}
\citation{m2fcn23}
\citation{13}
\citation{38}
\citation{m2fcn13}
\citation{m2fcn19}
\citation{15}
\citation{18}
\citation{31}
\citation{m2fcn26}
\citation{40}
\citation{43}
\citation{m2fcn}
\citation{m2fcn8}
\citation{29}
\citation{28}
\citation{11}
\citation{vd2d3d}
\citation{m2fcn1}
\citation{m2fcn8}
\citation{m2fcn29}
\citation{resnet}
\citation{m2fcn28}
\citation{m2fcn11}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Neuronal Boundary Detection in EM Images}{11}{section.2.3}}
\citation{m2fcn21}
\citation{m2fcn21}
\citation{m2fcn21}
\citation{m2fcn21}
\citation{m2fcn21}
\citation{piriform}
\citation{isbi2012}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Illustration of VD2D3D, a recursive deep network with the stepwise training.\relax }}{12}{figure.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{vd2d3d}{{2.1}{12}{Illustration of VD2D3D, a recursive deep network with the stepwise training.\relax }{figure.caption.7}{}}
\citation{hed}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{15}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{methodology}{{3}{15}{Methodology}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Network Structure}{15}{section.3.1}}
\newlabel{network structure}{{3.1}{15}{Network Structure}{section.3.1}{}}
\citation{hed}
\citation{vgg}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Three types of cascade-like networks: (a) cascaded network with single-recursive input; (b) cascaded network with multi-recursive inputs; (c) single-stage network with recursive inputs to fine-tune itself.\relax }}{16}{figure.caption.8}}
\newlabel{cascade_structures}{{3.1}{16}{Three types of cascade-like networks: (a) cascaded network with single-recursive input; (b) cascaded network with multi-recursive inputs; (c) single-stage network with recursive inputs to fine-tune itself.\relax }{figure.caption.8}{}}
\citation{hed}
\citation{hed}
\citation{hed}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Training Phase}{17}{section.3.2}}
\newlabel{training phase}{{3.2}{17}{Training Phase}{section.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Illustration of the proposed cascaded fully convolutional network for object boundary detection.\relax }}{18}{figure.caption.9}}
\newlabel{network}{{3.2}{18}{Illustration of the proposed cascaded fully convolutional network for object boundary detection.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Formulation of the Multi-recursive-input}{18}{subsection.3.2.1}}
\citation{m2fcn42}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Loss Function}{19}{subsection.3.2.2}}
\newlabel{fusion of subnet}{{3.4}{20}{Loss Function}{equation.3.2.4}{}}
\citation{m2fcn13}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Testing Phase}{21}{section.3.3}}
\newlabel{testing phase}{{3.3}{21}{Testing Phase}{section.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Model Interpretation}{21}{section.3.4}}
\newlabel{interpretation}{{3.4}{21}{Model Interpretation}{section.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Cascaded Architecture \emph  {vs.} Single-stage Architecture}{21}{subsection.3.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Multi-recursive-input \emph  {vs.} Single-recursive-input.\relax }}{22}{figure.caption.10}}
\newlabel{multi recursive input}{{3.3}{22}{Multi-recursive-input \emph {vs.} Single-recursive-input.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Multi-recursive-input \emph  {vs.} Single-recursive-input}{23}{subsection.3.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}End-to-end Training \emph  {vs.} Stepwise Self-tuning}{23}{subsection.3.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Prediction exmaples from different side-outputs and fused outputs in different stages.\relax }}{24}{figure.caption.11}}
\newlabel{interpretation}{{3.4}{24}{Prediction exmaples from different side-outputs and fused outputs in different stages.\relax }{figure.caption.11}{}}
\citation{piriform}
\citation{isbi12}
\citation{cedn}
\citation{m2fcn43}
\citation{vd2d3d}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experiments}{25}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{experiments}{{4}{25}{Experiments}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Neuronal Boundary Detection in EM Images}{25}{section.4.1}}
\citation{deep skeleton}
\citation{vd2d3d}
\citation{isbi12}
\citation{watershed}
\citation{vd2d3d}
\citation{isbi12}
\citation{watershed}
\citation{vd2d3d}
\citation{m2fcn13}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Evaluation Metric}{26}{subsection.4.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Mouse Piriform Cortex Dataset}{26}{subsection.4.1.2}}
\newlabel{experiment of piriform}{{4.1.2}{26}{Mouse Piriform Cortex Dataset}{subsection.4.1.2}{}}
\citation{fcn}
\citation{hed}
\citation{deep skeleton}
\citation{imagenet}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces (b)Neuronal boundary detection and (c) segmentation can be easily converted from each other, which we used in the experiments to training and testing on Mouse Piriform Cortex Dataset\cite  {vd2d3d} and ISBI 2012 EM Segmentation Dataset\cite  {isbi12}. (1) By applying the graph-based algorithms such as watershed\cite  {watershed}, we can transfer the boundary prediction into segmentation. (2) By calculating the 2D gradient in the segmentation ground-truth, the boundary annotation can be obtained. \relax }}{27}{figure.caption.12}}
\newlabel{segmentation and boundary}{{4.1}{27}{(b)Neuronal boundary detection and (c) segmentation can be easily converted from each other, which we used in the experiments to training and testing on Mouse Piriform Cortex Dataset\cite {vd2d3d} and ISBI 2012 EM Segmentation Dataset\cite {isbi12}. (1) By applying the graph-based algorithms such as watershed\cite {watershed}, we can transfer the boundary prediction into segmentation. (2) By calculating the 2D gradient in the segmentation ground-truth, the boundary annotation can be obtained. \relax }{figure.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Mouse Piriform Cortex Dataset\relax }}{27}{table.caption.13}}
\newlabel{piriform}{{4.1}{27}{Mouse Piriform Cortex Dataset\relax }{table.caption.13}{}}
\citation{sgd}
\citation{vd2d3d}
\citation{vd2d3d}
\citation{vd2d3d}
\citation{n4}
\citation{vd2d3d}
\citation{vd2d3d}
\citation{vd2d3d}
\citation{vd2d3d}
\citation{vd2d3d}
\citation{ialic}
\citation{resnet}
\citation{resnet}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Rand F-scores on Mouse Piriform Cortex Dataset\cite  {vd2d3d}\relax }}{29}{table.caption.14}}
\newlabel{outcome}{{4.2}{29}{Rand F-scores on Mouse Piriform Cortex Dataset\cite {vd2d3d}\relax }{table.caption.14}{}}
\newlabel{piriform fscore}{{4.2}{29}{Rand F-scores on Mouse Piriform Cortex Dataset\cite {vd2d3d}\relax }{table.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}ISBI 2012 EM Segmentation Dataset}{29}{subsection.4.1.3}}
\citation{cedn}
\citation{cedn}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Precision (rand merge)-recall (rand split) curves on Mouse Piriform Cortex Dataset\cite  {vd2d3d}. Our 3-stage network outperforms all the previous works on this dataset.\relax }}{30}{figure.caption.15}}
\newlabel{piriform prcurve}{{4.2}{30}{Precision (rand merge)-recall (rand split) curves on Mouse Piriform Cortex Dataset\cite {vd2d3d}. Our 3-stage network outperforms all the previous works on this dataset.\relax }{figure.caption.15}{}}
\citation{deep skeleton}
\citation{cedn}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Examples selected from PASCAL VOC Contour Dataset\cite  {cedn}. There are various objects (human, artificialities, animals, plants, etc.) appearing in complex scenes (indoor and outdoor environments, colorful backgrounds, blurs, textural confusions, etc), which significantly increases the difficulty of detecting the object-level boundary.\relax }}{31}{figure.caption.16}}
\newlabel{voc contour}{{4.3}{31}{Examples selected from PASCAL VOC Contour Dataset\cite {cedn}. There are various objects (human, artificialities, animals, plants, etc.) appearing in complex scenes (indoor and outdoor environments, colorful backgrounds, blurs, textural confusions, etc), which significantly increases the difficulty of detecting the object-level boundary.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Object Boundary Detection in Natural Images}{31}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Metrics}{31}{subsection.4.2.1}}
\citation{deep skeleton}
\citation{cedn}
\citation{densecrf}
\citation{cedn}
\citation{cedn}
\citation{fcn}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}PASCAL VOC Contour Dataset}{32}{subsection.4.2.2}}
\citation{hed}
\citation{sgd}
\citation{cedn}
\citation{cedn}
\citation{mcg}
\citation{se}
\citation{hed}
\citation{cedn}
\citation{cedn}
\citation{cedn}
\citation{mcg}
\citation{mcg}
\citation{se}
\citation{hed}
\citation{cedn}
\citation{cedn}
\citation{cedn}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Object boundary detection evaluation comparison on PASCAL VOC Contour Dataset\cite  {cedn}. Our proposed 3-stage cascaded fully convolutional network achieves the new state-of-the-art on this benchmark, with a significant improvement (around 2\% over the second)).\relax }}{34}{table.caption.17}}
\newlabel{outcome}{{4.3}{34}{Object boundary detection evaluation comparison on PASCAL VOC Contour Dataset\cite {cedn}. Our proposed 3-stage cascaded fully convolutional network achieves the new state-of-the-art on this benchmark, with a significant improvement (around 2\% over the second)).\relax }{table.caption.17}{}}
\newlabel{voc fscore}{{4.3}{34}{Object boundary detection evaluation comparison on PASCAL VOC Contour Dataset\cite {cedn}. Our proposed 3-stage cascaded fully convolutional network achieves the new state-of-the-art on this benchmark, with a significant improvement (around 2\% over the second)).\relax }{table.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Precision-recall curves on PASCAL VOC Contour Dataset\cite  {cedn}.\relax }}{35}{figure.caption.18}}
\newlabel{voc prcurve}{{4.4}{35}{Precision-recall curves on PASCAL VOC Contour Dataset\cite {cedn}.\relax }{figure.caption.18}{}}
\bibstyle{IEEEtran}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusions}{37}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{conclusions}{{5}{37}{Conclusions}{chapter.5}{}}
\bibdata{LUOreference}
\bibcite{vapnik2013nature}{1}
\bibcite{brucher2002document}{2}
\bibcite{kwon2003text}{3}
\bibcite{le2014distributed}{4}
\bibcite{zhang2015character}{5}
\bibcite{kim2014convolutional}{6}
\bibcite{johnson2015semi}{7}
\bibcite{mikolov2010recurrent}{8}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{39}{section*.19}}
\bibcite{xiao2016chinese}{9}
\bibcite{tang2015document}{10}
\bibcite{lai2015recurrent}{11}
\bibcite{wang2016learning}{12}
\bibcite{wang2016semantic}{13}
\bibcite{liu2016recurrent}{14}
\bibcite{graves2005framewise}{15}
\bibcite{nair2010rectified}{16}
\bibcite{he2015deep}{17}
\bibcite{graves2013speech}{18}
\bibcite{chung2015gated}{19}
\bibcite{kingma2014adam}{20}
\bibcite{socher2013recursive}{21}
\bibcite{li2002learning}{22}
\bibcite{kalchbrenner2014convolutional}{23}
\bibcite{irsoy2014deep}{24}
\bibcite{tai2015improved}{25}
\bibcite{zhou2015c}{26}
\bibcite{hinton2012improving}{27}
